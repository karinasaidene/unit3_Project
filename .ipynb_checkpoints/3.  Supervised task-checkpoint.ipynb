{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc183445",
   "metadata": {},
   "source": [
    "<img src=\"Logo.png\" width=\"100\" align=\"left\"/> \n",
    "\n",
    "# <center> Unit 3 Project </center>\n",
    "#  <center> Third section : supervised task </center>\n",
    "\n",
    "In this notebook you will be building and training a supervised learning model to classify your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be234200",
   "metadata": {},
   "source": [
    "For this task we will be using another classification model \"The random forests\" model.\n",
    "\n",
    "Steps for this task: \n",
    "1. Load the already clustered dataset \n",
    "2. Take into consideration that in this task we will not be using the already added column \"Cluster\" \n",
    "3. Split your data.\n",
    "3. Build your model using the SKlearn RandomForestClassifier class \n",
    "4. classify your data and test the performance of your model \n",
    "5. Evaluate the model ( accepted models should have at least an accuracy of 86%). Play with hyper parameters and provide a report about that.\n",
    "6. Provide evidence on the quality of your model (not overfitted good metrics)\n",
    "7. Create a new test dataset that contains the testset + an additional column called \"predicted_class\" stating the class predicted by your random forest classifier for each data point of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca14fca",
   "metadata": {},
   "source": [
    "## 1. Load the data and split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34235ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b318b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To-Do:  load the data \n",
    "df = pd.read_csv(\"HepatitisCdata_2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2bdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : keep only the columns to be used : all features except ID, cluster \n",
    "df1 = df.iloc[:,1:14]\n",
    "df1\n",
    "import numpy as np\n",
    "X=np.array(df1)\n",
    "#extract the target which is in our case Category column\n",
    "y=df['Category']\n",
    "# The target here is the Category column \n",
    "# Do not forget to split your data (this is a classification task)\n",
    "\n",
    "# test set size should be 20% of the data \n",
    "\n",
    "#here I m going to split the data set into training and testing subest\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "print(X_train.shape,\n",
    "      X_test.shape,\n",
    "      y_train.shape ,\n",
    "      y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523519ae",
   "metadata": {},
   "source": [
    "## 2. Building the model and training and evaluate the performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea837ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do build the model and train it \n",
    "# note that you will be providing explanation about the hyper parameter tuning \n",
    "# So you will be iterating a number of times before getting the desired performance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we are going to use Search Grid to tune the hyper parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#set the parameters by cross-validation\n",
    "bootstrap= [True]\n",
    "max_depth =[80, 90, 100, 110]\n",
    "max_features =[2, 3,5,12]\n",
    "min_samples_leaf =[3, 4, 5]\n",
    "min_samples_split =[5,8, 10, 12]\n",
    "n_estimators =[5,100, 200, 300, 1000] \n",
    "criterion='entropy'\n",
    "\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest Classifier\n",
    "dfrst = RandomForestClassifier(n_estimators=n_estimators,random_state=0)\n",
    "# Instantiate the grid search model\n",
    "grid = GridSearchCV(estimator=dfrst, param_grid=param_grid, cv = 5)\n",
    "#here I am going to train  the model\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa89cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best decision forest \n",
    "best_clf = grid.best_estimator_\n",
    "yhat = grid.predict(X_test)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do : evaluate the model in terms of accuracy and precision \n",
    "# Provide evidence that your model is not overfitting \n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "print(\"accuracy = \",accuracy_score(y_test,yhat))\n",
    "print(\"precision = \",precision_score(y_test,yhat,average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55598bf2",
   "metadata": {},
   "source": [
    "> Hint : A Perfect accuracy on the train set suggest that we have an overfitted model So the student should be able to provide a detailed table about the hyper parameters / parameters tuning with a good conclusion stating that the model has at least an accuracy of 86% on the test set without signs of overfitting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd49b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9a41c",
   "metadata": {},
   "source": [
    "## 3. Create the summary test set with the additional predicted class column: \n",
    "In this part you need to add the predicted class as a column to your test dataframe and save this one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : create the complete test dataframe : it should contain all the feature column + the actual target and the ID as wel\n",
    "df1 = df.iloc[:,0:15]\n",
    "x=np.array(df1)\n",
    "Y=df['Category']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,Y,test_size=0.2,random_state=0)\n",
    "test_df=pd.DataFrame(x_test, columns = ['ID','Category','Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA',\n",
    "       'GGT', 'PROT', 'cluster'])\n",
    "#test_df[\"Category\"] = pd.Series(y_test, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : Add the predicted_class column \n",
    "test_df[\"Predicted_class\"] = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bf1ca",
   "metadata": {},
   "source": [
    "> Make sure you have 16 column in this test set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be707260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f354df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test set \n",
    "test_df.to_csv(\"test_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d84f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
